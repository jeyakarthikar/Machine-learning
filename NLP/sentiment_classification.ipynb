{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uzwcnkz7IS2",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPlMqyWPjd5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing required libraries\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU2ck6ux7UWi",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvEOUSuwBBN6",
        "colab_type": "text"
      },
      "source": [
        "##IMDB Movie reviews sentiment classification\n",
        "Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkj6OshbjoWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMWIHEAnkCSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000 #vocab size\n",
        "maxlen = 300  #number of word used from each review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjPn1l5QlLYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1fe045f1-19f5-4f62-a04c-52c3c0ecf2b0"
      },
      "source": [
        "#load dataset as a list of ints\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7isG7zsklMYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make all sequences of the same length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test =  pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72pZEFA7lny1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62GROehf7g2i",
        "colab_type": "text"
      },
      "source": [
        "## Understanding the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mecY7B1_lzk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4dbb02ec-99b8-46a8-9809-f58a373644c0"
      },
      "source": [
        "#check the train shape\n",
        "x_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC25s3NMl563",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "4b2020bc-2a8f-4924-8109-87a9a734ca69"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    1,   14,   22,   16,   43,  530,\n",
              "        973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,  173,   36,\n",
              "        256,    5,   25,  100,   43,  838,  112,   50,  670,    2,    9,\n",
              "         35,  480,  284,    5,  150,    4,  172,  112,  167,    2,  336,\n",
              "        385,   39,    4,  172, 4536, 1111,   17,  546,   38,   13,  447,\n",
              "          4,  192,   50,   16,    6,  147, 2025,   19,   14,   22,    4,\n",
              "       1920, 4613,  469,    4,   22,   71,   87,   12,   16,   43,  530,\n",
              "         38,   76,   15,   13, 1247,    4,   22,   17,  515,   17,   12,\n",
              "         16,  626,   18,    2,    5,   62,  386,   12,    8,  316,    8,\n",
              "        106,    5,    4, 2223, 5244,   16,  480,   66, 3785,   33,    4,\n",
              "        130,   12,   16,   38,  619,    5,   25,  124,   51,   36,  135,\n",
              "         48,   25, 1415,   33,    6,   22,   12,  215,   28,   77,   52,\n",
              "          5,   14,  407,   16,   82,    2,    8,    4,  107,  117, 5952,\n",
              "         15,  256,    4,    2,    7, 3766,    5,  723,   36,   71,   43,\n",
              "        530,  476,   26,  400,  317,   46,    7,    4,    2, 1029,   13,\n",
              "        104,   88,    4,  381,   15,  297,   98,   32, 2071,   56,   26,\n",
              "        141,    6,  194, 7486,   18,    4,  226,   22,   21,  134,  476,\n",
              "         26,  480,    5,  144,   30, 5535,   18,   51,   36,   28,  224,\n",
              "         92,   25,  104,    4,  226,   65,   16,   38, 1334,   88,   12,\n",
              "         16,  283,    5,   16, 4472,  113,  103,   32,   15,   16, 5345,\n",
              "         19,  178,   32], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvFthFx-l6pY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "801874b4-1255-4930-8495-322bb92e7171"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nks25IQmDzL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56053675-8f53-46df-821a-c4e891269ca5"
      },
      "source": [
        "y_train[0:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE72zuVcmGRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdf02142-228f-4bb7-8ddd-d6e9f65ee0fb"
      },
      "source": [
        "x_test.shape "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6gAOF01mO5g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "655c6a9c-4e65-4e27-abd9-453a2f330c30"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu3zfog57n-5",
        "colab_type": "text"
      },
      "source": [
        "There are 25000 data for training and 25000 data records for testing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa6o6GgP71FC",
        "colab_type": "text"
      },
      "source": [
        "## Building the model along with the embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLgw1K7S8IyA",
        "colab_type": "text"
      },
      "source": [
        "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn LabelEncoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACEfiGsi8Mde",
        "colab_type": "text"
      },
      "source": [
        "## Building an LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u68a95s_mRV8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "fa90945e-973f-4498-9f93-c40f94ea8ae8"
      },
      "source": [
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF0SnKBgCyQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "72bc587d-0d07-46af-f1da-b0556785f9f5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         1280000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,411,713\n",
            "Trainable params: 1,411,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5izeLrJxmyBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyHPx3iZnBrc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "250c2165-6c5d-42d3-b2b7-e3eda7099259"
      },
      "source": [
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=15,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/15\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "25000/25000 [==============================] - 460s 18ms/step - loss: 0.4757 - acc: 0.7762 - val_loss: 0.3769 - val_acc: 0.8403\n",
            "Epoch 2/15\n",
            "25000/25000 [==============================] - 453s 18ms/step - loss: 0.3607 - acc: 0.8495 - val_loss: 0.4914 - val_acc: 0.8314\n",
            "Epoch 3/15\n",
            "25000/25000 [==============================] - 455s 18ms/step - loss: 0.2864 - acc: 0.8851 - val_loss: 0.3529 - val_acc: 0.8584\n",
            "Epoch 4/15\n",
            "25000/25000 [==============================] - 461s 18ms/step - loss: 0.2158 - acc: 0.9168 - val_loss: 0.3427 - val_acc: 0.8664\n",
            "Epoch 5/15\n",
            "25000/25000 [==============================] - 456s 18ms/step - loss: 0.1712 - acc: 0.9375 - val_loss: 0.3709 - val_acc: 0.8703\n",
            "Epoch 6/15\n",
            "25000/25000 [==============================] - 456s 18ms/step - loss: 0.1290 - acc: 0.9540 - val_loss: 0.4011 - val_acc: 0.8681\n",
            "Epoch 7/15\n",
            "25000/25000 [==============================] - 462s 18ms/step - loss: 0.1309 - acc: 0.9535 - val_loss: 0.3835 - val_acc: 0.8621\n",
            "Epoch 8/15\n",
            "25000/25000 [==============================] - 467s 19ms/step - loss: 0.0822 - acc: 0.9720 - val_loss: 0.4518 - val_acc: 0.8676\n",
            "Epoch 9/15\n",
            "25000/25000 [==============================] - 461s 18ms/step - loss: 0.0560 - acc: 0.9815 - val_loss: 0.5123 - val_acc: 0.8526\n",
            "Epoch 10/15\n",
            "25000/25000 [==============================] - 456s 18ms/step - loss: 0.0428 - acc: 0.9864 - val_loss: 0.6071 - val_acc: 0.8617\n",
            "Epoch 11/15\n",
            "25000/25000 [==============================] - 456s 18ms/step - loss: 0.0332 - acc: 0.9894 - val_loss: 0.5986 - val_acc: 0.8470\n",
            "Epoch 12/15\n",
            "25000/25000 [==============================] - 463s 19ms/step - loss: 0.0265 - acc: 0.9916 - val_loss: 0.6939 - val_acc: 0.8632\n",
            "Epoch 13/15\n",
            "25000/25000 [==============================] - 458s 18ms/step - loss: 0.0199 - acc: 0.9935 - val_loss: 0.6492 - val_acc: 0.8605\n",
            "Epoch 14/15\n",
            "25000/25000 [==============================] - 454s 18ms/step - loss: 0.0161 - acc: 0.9951 - val_loss: 0.7849 - val_acc: 0.8598\n",
            "Epoch 15/15\n",
            "25000/25000 [==============================] - 457s 18ms/step - loss: 0.0163 - acc: 0.9948 - val_loss: 0.7139 - val_acc: 0.8601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8d61f0e048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tm2C9Hi8Xec",
        "colab_type": "text"
      },
      "source": [
        "The model has got good accuracy on the training. Let us see how it works on testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6ceJ4JCCQHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "482a7302-79de-4bd6-ef69-547eea000df3"
      },
      "source": [
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 69s 3ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHtR5EsSCimA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "38915875-7331-4cbb-be2d-b6baafc6e82d"
      },
      "source": [
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.7138513833588361\n",
            "Test accuracy: 0.86008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPk5ib7j8fzs",
        "colab_type": "text"
      },
      "source": [
        "The testing accuracy is very less compared to training accuracy. This may be due to the fact that large number of training parameters or it may also be due to the fact that we chose smaller vocabulary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FavpRpPn9C9x",
        "colab_type": "text"
      },
      "source": [
        "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zy2e-e6DPJK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "df12e66f-69ec-41d8-d630-21f057a47ae0"
      },
      "source": [
        "for idx, layer in enumerate(model.layers):\n",
        "  print(model.layers[idx].output)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"embedding_1/embedding_lookup/Identity:0\", shape=(?, ?, 128), dtype=float32)\n",
            "Tensor(\"lstm_1/TensorArrayReadV3:0\", shape=(?, 128), dtype=float32)\n",
            "Tensor(\"dense_1/Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sA4gDOX9adf",
        "colab_type": "text"
      },
      "source": [
        "we are seeing the shape of the three tensors formed in our model. \n",
        "\n",
        "Let us build small models and predict the output of each layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqjgyGhPJHN4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "abf16144-834c-4e35-9226-f3f1f7146fe4"
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "#model for layer1\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer('embedding_1').output)\n",
        "intermediate_output = intermediate_layer_model.predict(x_test[0])\n",
        "print(intermediate_output.shape)\n",
        "print(intermediate_output)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300, 1, 128)\n",
            "[[[ 0.10009428  0.06586564 -0.1270075  ...  0.05326356  0.01376145\n",
            "   -0.07130247]]\n",
            "\n",
            " [[ 0.10009428  0.06586564 -0.1270075  ...  0.05326356  0.01376145\n",
            "   -0.07130247]]\n",
            "\n",
            " [[ 0.10009428  0.06586564 -0.1270075  ...  0.05326356  0.01376145\n",
            "   -0.07130247]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.07268848  0.06812154 -0.10390531 ...  0.04641328 -0.00473515\n",
            "    0.03089936]]\n",
            "\n",
            " [[ 0.11306102 -0.00706581 -0.11204792 ... -0.02783196 -0.02873449\n",
            "   -0.11377687]]\n",
            "\n",
            " [[ 0.04546463  0.09044972  0.11785187 ... -0.10651184  0.11764654\n",
            "   -0.09185338]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_B5e2deK4Ko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5754f37a-0b92-4cc8-c33b-79c6ca85773f"
      },
      "source": [
        "#model for layer2\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer('lstm_1').output)\n",
        "intermediate_output = intermediate_layer_model.predict(x_test[0])\n",
        "print(intermediate_output.shape)\n",
        "print(intermediate_output)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300, 128)\n",
            "[[ 0.00654792 -0.01969376 -0.06102571 ... -0.14492716 -0.01894907\n",
            "  -0.02714133]\n",
            " [ 0.00654792 -0.01969376 -0.06102571 ... -0.14492716 -0.01894907\n",
            "  -0.02714133]\n",
            " [ 0.00654792 -0.01969376 -0.06102571 ... -0.14492716 -0.01894907\n",
            "  -0.02714133]\n",
            " ...\n",
            " [-0.01300291  0.0036605  -0.05254975 ... -0.09516702  0.03453996\n",
            "  -0.01613788]\n",
            " [ 0.00852975 -0.00619132 -0.00311589 ...  0.05427508 -0.04054945\n",
            "   0.00287724]\n",
            " [-0.04903843 -0.08219673 -0.23726662 ... -0.06947719 -0.13758294\n",
            "  -0.08548969]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv2VTYtMLB2y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a93e0734-47b6-47b5-e033-1bce0ad3a0fb"
      },
      "source": [
        "#model for layer3\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer('dense_1').output)\n",
        "intermediate_output = intermediate_layer_model.predict(x_test[0])\n",
        "print(intermediate_output.shape)\n",
        "print(intermediate_output)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300, 1)\n",
            "[[4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692905e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [4.0692908e-01]\n",
            " [6.6610563e-01]\n",
            " [4.0441960e-01]\n",
            " [8.5452843e-01]\n",
            " [2.0852992e-01]\n",
            " [4.4858119e-01]\n",
            " [6.6458881e-01]\n",
            " [5.4381835e-01]\n",
            " [6.3790309e-01]\n",
            " [6.3790309e-01]\n",
            " [5.4471850e-01]\n",
            " [5.4471850e-01]\n",
            " [6.7066252e-01]\n",
            " [6.8809116e-01]\n",
            " [1.7952806e-01]\n",
            " [5.7757908e-01]\n",
            " [6.8809116e-01]\n",
            " [3.4528911e-02]\n",
            " [9.9407029e-01]\n",
            " [2.9280782e-04]\n",
            " [8.5545659e-01]\n",
            " [6.8809116e-01]\n",
            " [3.9650521e-01]\n",
            " [4.7276258e-01]\n",
            " [2.0914793e-02]\n",
            " [2.0914793e-02]\n",
            " [2.0914793e-02]\n",
            " [6.3790309e-01]\n",
            " [6.3790309e-01]\n",
            " [6.5644622e-01]\n",
            " [7.3541337e-01]\n",
            " [9.9350280e-01]\n",
            " [6.8505967e-01]\n",
            " [1.5138751e-01]\n",
            " [9.8284173e-01]\n",
            " [1.7994225e-02]\n",
            " [8.4240913e-01]\n",
            " [5.2033770e-01]\n",
            " [2.0852992e-01]\n",
            " [4.4858119e-01]\n",
            " [5.7246351e-01]\n",
            " [8.3273840e-01]\n",
            " [1.9338399e-01]\n",
            " [9.1438341e-01]\n",
            " [1.9790754e-01]\n",
            " [5.5011785e-01]\n",
            " [8.0048662e-01]\n",
            " [9.9350280e-01]\n",
            " [2.0852992e-01]\n",
            " [5.7214224e-01]\n",
            " [1.2854862e-01]\n",
            " [8.0048662e-01]\n",
            " [8.4708095e-01]\n",
            " [6.4992326e-01]\n",
            " [6.7066252e-01]\n",
            " [8.3273840e-01]\n",
            " [1.3066801e-01]\n",
            " [4.2162228e-01]\n",
            " [8.0266285e-01]\n",
            " [5.4471850e-01]\n",
            " [8.9993459e-01]\n",
            " [7.3735625e-01]\n",
            " [4.6618924e-01]\n",
            " [9.8284173e-01]\n",
            " [7.7193874e-01]\n",
            " [8.5452843e-01]\n",
            " [2.0852987e-01]\n",
            " [6.6458881e-01]\n",
            " [5.4381835e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUQnsOIHOD0y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "055ac2d8-148a-4855-8e16-f9792587febb"
      },
      "source": [
        "#Let us predict the output for a test sample\n",
        "p = model.predict(x_test[5000])\n",
        "p = np.argmax(p, axis=-1)[0]\n",
        "print(p)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qURS57KX-AXm",
        "colab_type": "text"
      },
      "source": [
        "The output comes to be 0 which means that the review is classified as negative. Let us see how the input was."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUmdUYGDSI4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "79105b89-6c39-4650-ffa9-fe2ac5fcedc0"
      },
      "source": [
        "x_test[0]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    1,  591,  202,   14,   31,    6,  717,   10,   10,    2,\n",
              "          2,    5,    4,  360,    7,    4,  177, 5760,  394,  354,    4,\n",
              "        123,    9, 1035, 1035, 1035,   10,   10,   13,   92,  124,   89,\n",
              "        488, 7944,  100,   28, 1668,   14,   31,   23,   27, 7479,   29,\n",
              "        220,  468,    8,  124,   14,  286,  170,    8,  157,   46,    5,\n",
              "         27,  239,   16,  179,    2,   38,   32,   25, 7944,  451,  202,\n",
              "         14,    6,  717], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdBX5z56_Oq3",
        "colab_type": "text"
      },
      "source": [
        "##Understanding the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFuQ_mY7RM3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "662cd4f2-5836-4760-876e-4de937386f62"
      },
      "source": [
        "# download the key,value pair formed by the imdb dataset\n",
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDaENNT8RY41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# forming a reverse key index to get the word for each designated index\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXzWfhoDRoUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "61f59f61-0b5c-49a2-fe92-e97626f63f68"
      },
      "source": [
        "# checkin one test data see how the transformation is done\n",
        "review_text = ' '.join([reverse_word_index.get(i, '?') for i in x_test[0]])\n",
        "print(review_text)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? the wonder own as by is sequence i i and and to of hollywood br of down shouting getting boring of ever it sadly sadly sadly i i was then does don't close faint after one carry as by are be favourites all family turn in does as three part in another some to be probably with world and her an have faint beginning own as is sequence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3iWHCGE_2w_",
        "colab_type": "text"
      },
      "source": [
        "Let us create a custom function to do all these steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJs8L39OXX6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_test_result(model,test_data_index):\n",
        "  data = x_test[test_data_index]\n",
        "  p = model.predict_classes(data)\n",
        "  p = np.argmax(p, axis=-1)[0]\n",
        "  label = \"Positive\" if p else \"Negative\"   \n",
        "  print(\"The sentiment of the review is: \" +label)\n",
        "  given_label = \"Positive\" if y_test[test_data_index] else \"Negative\"   \n",
        "  print(\"The sentiment value  for the review provided in the data is: \" +given_label)\n",
        "  review_text = ' '.join([reverse_word_index.get(i, '?') for i in data])\n",
        "  print(\"Review_text:\")\n",
        "  print(review_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBVEros7X_JT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b62760b8-efa8-43be-b299-20ae08a38c71"
      },
      "source": [
        "print_test_result(model,0)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentiment of the review is: Negative\n",
            "The sentiment value  for the review provided in the data is: Negative\n",
            "Review_text:\n",
            "? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? the wonder own as by is sequence i i and and to of hollywood br of down shouting getting boring of ever it sadly sadly sadly i i was then does don't close faint after one carry as by are be favourites all family turn in does as three part in another some to be probably with world and her an have faint beginning own as is sequence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2EeFhrsZNNJ",
        "colab_type": "text"
      },
      "source": [
        "The review text has many words like \"sadly\",\"down\",\"boring\", \"faint beginning\".\n",
        "our model has correctly classified this review as negative.\n",
        "\n",
        "Let us check few more examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1GYdVliaC_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "29542a86-0521-4432-e6c3-538a837bea57"
      },
      "source": [
        "print_test_result(model,1267)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentiment of the review is: Negative\n",
            "The sentiment value  for the review provided in the data is: Positive\n",
            "Review_text:\n",
            "br another all there bit or is heartbreaking this foul in is psychotic bargain this called calls and to her plot and all it by naval was had saying what all me good up female this of how lot br of on movie much of versions this of on it who and meredith start and to and anywhere would different had version to myers of almost br is killer br am production film now leg would lines have is franchise br sing expectations found like it disappointed this fellow not these possessed no that trying in about altman execution race i i of younger br awful there will secret who and would to about and young and of br italian hospital and would there had unique each but of being not more he gets no would it his turns in practically film of night of and plane br about acting game in kathryn this twisted to that there will see stumbles violent i i of on game in tomorrow world is again seems this by through whilst or of plenty young br is earnest piece in of grim br is power which this sing disappointed could've to other of dollars race this is and whole to was looking there apes in soundtrack jail of and br go would art movie is cagney this is clothing distinct trouble had lines want an is touching certainly br of class bad he her russell br i i much watch was vision italian hospital and more with is actor br and message we was children up some br as on in we marie that there will is deemed hate are of lot br going type again and isn't character but an though like just in can is money entertaining back film is police thinks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZVbfVgWabVa",
        "colab_type": "text"
      },
      "source": [
        "even this text has many negative words like \"disappointed\",\"stumbles\",\"awful\"\n",
        "our model has predicted it as negative.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC0rQ5oebAhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8ce53c36-dd1a-4e6c-ecc3-11dd131173ca"
      },
      "source": [
        "print_test_result(model,8000)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentiment of the review is: Negative\n",
            "The sentiment value  for the review provided in the data is: Positive\n",
            "Review_text:\n",
            "scene that story at definitely mainly go all whereas up been and are of quit to of degree then totally movie emotional scene i'm that an and simple best era in and of seemed edison br of their movie was takes all well hugo in think gives this and all and of and and gives br and this reliable and all satisfying of equally past br levels making first of bother adaption better of and lived badly gives 7 to and specific is guess br said making scene take all end doc this minutes be simple limp hours or and 7 in wal and to and in footage and in gielgud ripped gives and to worst these of ever comedies edward whose which old that and up older been think yourself must this that these it is stayed rarely are of and br finds popular scene it know as on find is themes this witness of and april this really all high some br terrifying but be appearances comedy that of fat it out is possessed ben to as climax come it for more he even review sign give fix to of fat eventually movies etc of dire br our in 000 jenny but were unusual to fix ordinary dvd this be flow as it much hear some who of dollar and br of stayed worst and and br and fix once of ever film fix to and streep or of crude in stupid want for of here it of every this is young truly br secretly and see secretly petty of 9 br and fix all sides is seemed to is mamet moment in sun popular action michael in number not seeing end that to deaf movie much movie and movie and fix of faithful and br camping hot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwJBMBZqdVBs",
        "colab_type": "text"
      },
      "source": [
        "# Building bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmbxbmUzd4tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bidirectional_model = Sequential()\n",
        "bidirectional_model.add(Embedding(vocab_size, 128, input_length=maxlen))\n",
        "bidirectional_model.add(Bidirectional(LSTM(64)))\n",
        "bidirectional_model.add(Dropout(0.5))\n",
        "bidirectional_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "bidirectional_model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-ntRwdgeInf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "f6571b04-1c21-4ec0-83f9-89d4cd3e7ab4"
      },
      "source": [
        "print(bidirectional_model.summary())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 300, 128)          1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rRL6TYDeHOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "5a2cab67-5464-4c36-ddc2-8a8bb5ee3508"
      },
      "source": [
        "\n",
        "print('Train...')\n",
        "bidirectional_model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=10,\n",
        "          validation_data=[x_test, y_test])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 460s 18ms/step - loss: 0.1225 - acc: 0.9572 - val_loss: 0.4173 - val_acc: 0.8542\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 452s 18ms/step - loss: 0.1185 - acc: 0.9577 - val_loss: 0.4216 - val_acc: 0.8610\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 458s 18ms/step - loss: 0.0946 - acc: 0.9667 - val_loss: 0.4748 - val_acc: 0.8588\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 469s 19ms/step - loss: 0.0640 - acc: 0.9794 - val_loss: 0.4890 - val_acc: 0.8474\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 468s 19ms/step - loss: 0.0451 - acc: 0.9858 - val_loss: 0.6230 - val_acc: 0.8450\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 454s 18ms/step - loss: 0.0618 - acc: 0.9783 - val_loss: 0.6251 - val_acc: 0.8598\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 460s 18ms/step - loss: 0.0407 - acc: 0.9878 - val_loss: 0.6279 - val_acc: 0.8625\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 460s 18ms/step - loss: 0.0241 - acc: 0.9927 - val_loss: 0.7489 - val_acc: 0.8600\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 455s 18ms/step - loss: 0.0241 - acc: 0.9930 - val_loss: 0.6978 - val_acc: 0.8271\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 451s 18ms/step - loss: 0.0360 - acc: 0.9883 - val_loss: 0.7200 - val_acc: 0.8582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8d5a57b1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqUNf1XRlmiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ba8c7cc-4ff1-43bb-cb5d-a4469ac5a390"
      },
      "source": [
        "score, acc = bidirectional_model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 67s 3ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoFPuYxSluIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "633bdc22-7b85-469a-e2d9-28947d43ecc1"
      },
      "source": [
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.720015089430213\n",
            "Test accuracy: 0.85816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjmO4SUZ7Ebt",
        "colab_type": "text"
      },
      "source": [
        "Though the training accuracy is very high , the test accuracy is poor than normal LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5d8EbZ9AO-4",
        "colab_type": "text"
      },
      "source": [
        "##Conclusion\n",
        "\n",
        "\n",
        "*   we have downloaded the IMDB dataset and performed sentiment analysis\n",
        "*   the vectorization of the model is done by keras itself\n",
        "*   Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers)\n",
        "* Two models are built , a LSTM model and a Bidirectional LSTM model\n",
        "* An embedding layer is added to each of the model to convert the sequence into feature vectors\n",
        "* Both the models performed well on training compared to testing\n",
        "* LSTM ( training accuracy - 0.9948     ; testing accuracy -   0.86)    \n",
        "* Bidirectional LSTM ( training accuracy - 0.9883   ; testing accuracy - 0.85816)   \n",
        "\n"
      ]
    }
  ]
}